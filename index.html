<!DOCTYPE html>
<html lang="en">
	<head>
		<title>three.js webgl - blender -json</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<style>
			body {
				background:#777;
				padding:0;
				margin:0;
				overflow:hidden;
			}

			#info {
				position: absolute;
				top: 0px;
				width: 100%;
				color: #ffffff;
			}

		</style>
	</head>
	<body>

		<div id="container"></div>

		<script src="js/three.js"></script>
		<script src="js/orbit-controls.js"></script>
		<script src="js/OBJLoader.js"></script>
		<script src="js/dat.gui.js"></script>

		
		  <script id="skyboxVS" type="x-shader/x-vertex">

	uniform mat4 modelMatrix;
	uniform mat4 viewMatrix;
      	uniform mat4 projectionMatrix;

     	attribute vec3 position; 

	varying vec3 vWorldPosition;
	
	void main() {

		vec4 worldPosition = modelMatrix * vec4( position, 1.0 );
		vWorldPosition = worldPosition.xyz;

		vec4 p = viewMatrix * modelMatrix * vec4(position, 1.0);
		gl_Position = projectionMatrix * p;
		
     	 }

    </script>


    <script id="skyboxFS" type="x-shader/x-fragment">

		precision mediump float;
		
		uniform samplerCube tCube;
		varying vec3 vWorldPosition;

		void main() {

			gl_FragColor = textureCube( tCube, vec3(  vWorldPosition ) );
		}
	
    </script>


  <script id="vertexShader" type="x-shader/x-vertex">

	uniform mat3 normalMatrix;
	uniform mat4 modelMatrix;
	uniform mat4 viewMatrix;
    uniform mat4 projectionMatrix;
	uniform vec3 cameraPosition;

	attribute vec4 vertex;
	attribute vec3 normal;
    attribute vec3 position; 
    attribute vec2 uv;

	varying vec3 worldNormal;
	varying vec3 incident;
	varying vec2 vUV;
	
	void main() {


		vUV = uv; 
		vec4 worldPosition = modelMatrix * vec4( position, 1.0 ); // world position
		worldNormal = normalize( mat3( modelMatrix[0].xyz, modelMatrix[1].xyz, modelMatrix[2].xyz ) * normal ); // world space normal
		incident = worldPosition.xyz - cameraPosition.xyz;
		
        vec4 mvPosition = viewMatrix * modelMatrix * vec4(position, 1.0); // model view position
		
		
		/*
		vRefraction = refract(incidentNormal,worldNormal,(rAir/rGlass));
		vReflection = reflect(incidentNormal,worldNormal);
		// Schlick's approximation of fresnel
		//vReflectionFactor = mFresnelBias + mFresnelScale * pow( 1.0 + dot( normalize( I ), worldNormal ), mFresnelPower);

		vFresnel = rIndex + (1.0 - rIndex) * pow((1.0-dot(-incidentNormal,worldNormal)),5.0);
		*/
		
        gl_Position = projectionMatrix * mvPosition; 
    }

    </script>


    <script id="fragmentShader" type="x-shader/x-fragment">

	precision mediump float;
	uniform samplerCube tCube;
	uniform float index1;
	uniform float index2;
	uniform float fresPower;
	uniform float fresBias;
	
	varying vec2 vUV;
	varying vec3 worldNormal;
	varying vec3 incident;


	// Schlick's approximation of fresnel
	// fresnelAngle = index + (1-cos(fresnelAngle))^5 * (1-index)
		float fresnelApprox(vec3 incident, vec3 normal)
		{
			float bias = ((index1 - index2)*(index1-index2))/((index1 + index2)*(index1+index2));
			float power = fresPower;
			float scale = 1.0 - bias;
			
			return bias + pow(1.0-dot(incident,normal),power)*scale; 
		}
	
	
	
      	void main() {
		//normalize vectors
		vec3 normal = normalize(worldNormal);
		vec3 incidentN = normalize(incident);
		
		// find reflection
		vec3 reflectV = normalize(reflect(incidentN,normal));
		vec3 reflectColor = textureCube(tCube,reflectV).xyz;
		// find refraction
		vec3 refractColor;
		refractColor.x = textureCube(tCube, refract(incidentN, normal, index2)).x;
		refractColor.y = textureCube(tCube, refract(incidentN, normal, index2-0.02)).y;
		refractColor.z = textureCube(tCube, refract(incidentN, normal, index2-0.04)).z;

		float fresnelEffect = fresnelApprox(-incidentN, normal);
		
        gl_FragColor = vec4(mix(refractColor, reflectColor, fresnelEffect),1.0);//c1; //, c2, 0.5);
	}

	</script>

	<script id="passthroughVS" type="x-shader/x-vertex">
	  uniform mat4 modelViewMatrix;
	  uniform mat4 projectionMatrix;

	  attribute vec3 position;
	  attribute vec2 uv;
	  
	  varying vec2 vUV;

	  void main() {
	    vUV = uv;
	    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
	  }
	</script>
	
	<script id="simulateCondensationFS" type="x-shader/x-fragment">
	  precision mediump float;

	  uniform vec2 textureSize; //The width and height of our screen
	  // x = velocity x with 0.0 = -1.0, 0.5 = 0.0, and 1.0 = 1.0
	  // y = velocity y
	  // z = volume of water in cm^3
	  uniform sampler2D waterSimulation;
	  uniform float time; //In S
	  uniform float deltaTime; //In S
	  uniform float condensationRate; //The rate at which noise is added to the volume each frame
	  uniform bool addWater; //If true, will add water to simulation
	  
	  varying vec2 vUV;
	  
	  
	  // START NOISE
	  // https://github.com/ashima/webgl-noise/blob/master/src/cellular2D.glsl
	  // Cellular noise ("Worley noise") in 2D in GLSL.
	  // Copyright (c) Stefan Gustavson 2011-04-19. All rights reserved.
	  // This code is released under the conditions of the MIT license.
	  // See LICENSE file for details.
	  // https://github.com/stegu/webgl-noise

	  // Modulo 289 without a division (only multiplications)
	  vec3 mod289(vec3 x) {
	    return x - floor(x * (1.0 / 289.0)) * 289.0;
	  }

	  vec2 mod289(vec2 x) {
	    return x - floor(x * (1.0 / 289.0)) * 289.0;
	  }

	  // Modulo 7 without a division
	  vec3 mod7(vec3 x) {
	    return x - floor(x * (1.0 / 7.0)) * 7.0;
	  }

	  // Permutation polynomial: (34x^2 + x) mod 289
	  vec3 permute(vec3 x) {
	    return mod289((34.0 * x + 1.0) * x);
	  }

	  // Cellular noise, returning F1 and F2 in a vec2.
	  // Standard 3x3 search window for good F1 and F2 values
	  vec2 cellular(vec2 P) {
	  #define K 0.142857142857 // 1/7
	  #define Ko 0.428571428571 // 3/7
	  #define jitter 1.0 // Less gives more regular pattern
	    vec2 Pi = mod289(floor(P));
	    vec2 Pf = fract(P);
	    vec3 oi = vec3(-1.0, 0.0, 1.0);
	    vec3 of = vec3(-0.5, 0.5, 1.5);
	    vec3 px = permute(Pi.x + oi);
	    vec3 p = permute(px.x + Pi.y + oi); // p11, p12, p13
	    vec3 ox = fract(p*K) - Ko;
	    vec3 oy = mod7(floor(p*K))*K - Ko;
	    vec3 dx = Pf.x + 0.5 + jitter*ox;
	    vec3 dy = Pf.y - of + jitter*oy;
	    vec3 d1 = dx * dx + dy * dy; // d11, d12 and d13, squared
	    p = permute(px.y + Pi.y + oi); // p21, p22, p23
	    ox = fract(p*K) - Ko;
	    oy = mod7(floor(p*K))*K - Ko;
	    dx = Pf.x - 0.5 + jitter*ox;
	    dy = Pf.y - of + jitter*oy;
	    vec3 d2 = dx * dx + dy * dy; // d21, d22 and d23, squared
	    p = permute(px.z + Pi.y + oi); // p31, p32, p33
	    ox = fract(p*K) - Ko;
	    oy = mod7(floor(p*K))*K - Ko;
	    dx = Pf.x - 1.5 + jitter*ox;
	    dy = Pf.y - of + jitter*oy;
	    vec3 d3 = dx * dx + dy * dy; // d31, d32 and d33, squared
	    // Sort out the two smallest distances (F1, F2)
	    vec3 d1a = min(d1, d2);
	    d2 = max(d1, d2); // Swap to keep candidates for F2
	    d2 = min(d2, d3); // neither F1 nor F2 are now in d3
	    d1 = min(d1a, d2); // F1 is now in d1
	    d2 = max(d1a, d2); // Swap to keep candidates for F2
	    d1.xy = (d1.x < d1.y) ? d1.xy : d1.yx; // Swap if smaller
	    d1.xz = (d1.x < d1.z) ? d1.xz : d1.zx; // F1 is in d1.x
	    d1.yz = min(d1.yz, d2.yz); // F2 is now not in d2.yz
	    d1.y = min(d1.y, d1.z); // nor in  d1.z
	    d1.y = min(d1.y, d2.x); // F2 is in d1.y, we're done.
	    return sqrt(d1.xy);
	  }
	  // END NOISE
	  
	  
	  // Dampen velocity to using gaussian-like function from
	  // From "A model for real-time on-surface flows" by J.-F. El Hajjar et al
	  float dampen(float number) {
	    return exp(-pow(1.0 - number, 4.0) / (0.1));
	  }
	  
	  // Velocity stored in the texture is scaled from 0.0-1.0
	  // this upscales it to -1.0-1.0
	  vec2 unscaleVelocity(vec2 v) {
	    return v;
	    return clamp((v - 0.5) * 2.0, -1.0, 1.0);
	  }
	  
	  // Converts -1.0-1.0 to 0.0-1.0
	  vec2 scaleVelocity(vec2 v) {
	    return v;
	    return clamp(v / 2.0 + 0.5, 0.0, 1.0);
	  }
	  
	  // Calculates the new velocity for a given pixel
	  // The result vectors are mapped from -1.0-1.0 to 0.0-1.0
	  vec2 velocity(vec2 pt, vec2 ptDelta) {
	    vec4 lastSim = texture2D(waterSimulation, pt);
	    
	    // Density * volume
	    // density of water = 1 g/cmÂ³
	    // Need to make it relative to cell size
	    float mass = lastSim.z;
	    // Assuming down is -y
	    // In CM/S^2 980.665
	    vec2 gravity = vec2(0.0, -980.0);
	    
	    vec2 acceleration = gravity/mass;
	    
	    vec2 newVelocity = unscaleVelocity(lastSim.xy) + acceleration * dampen(mass) * deltaTime;
	    
	    // The paper seems to say it should be sqrt(2.0) * ptDelta, but that doesn't work...
	    vec2 maxDisplacement = sqrt(2.0 * ptDelta);
	    // // vec2 maxDisplacement = sqrt(2.0) * ptDelta;
	    newVelocity =clamp(newVelocity, -maxDisplacement, maxDisplacement);
	    
	    return scaleVelocity(newVelocity);
	  }
	  
	  // Calculates the contribution to the current cell's volume
	  // by examining all adjacent cells.
	  // Parameters are the current point and the delta between points
	  float calcluateNewVolume(vec2 pt, vec2 ptDelta) {
	    // Adapted from A model for real-time on-surface flows by J.-F. El Hajjar et al 
	    
	    //Calculate the texture point for the current cell
	    vec2 ptC = pt;
	    //Use the point to calculate its velocity
	    vec2 v = unscaleVelocity(velocity(ptC, ptDelta));
	    // Find the cell's volume contribution to the pt cell
	    float newVolume = (1.0 - abs(v.x)) * (1.0 - abs(v.y)) * texture2D(waterSimulation, pt).z;
	    // Repeat for every adjacent cell
	    
	    ptC = vec2(max(pt.x - ptDelta.x, 0.0), min(pt.y + ptDelta.y, 1.0));
	    v = unscaleVelocity(velocity(ptC, ptDelta));
	    newVolume += max(0.0, v.x) * abs(min(0.0, v.y)) * texture2D(waterSimulation, ptC).z;
	    
	    ptC = vec2(pt.x, min(pt.y + ptDelta.y, 1.0));
	    v = unscaleVelocity(velocity(ptC, ptDelta));
	    newVolume += (1.0 - abs(v.x)) * abs(min(0.0, v.y)) * texture2D(waterSimulation, ptC).z;
	    
	    ptC = vec2(min(pt.x + ptDelta.x, 1.0), min(pt.y + ptDelta.y, 1.0));
	    v = unscaleVelocity(velocity(ptC, ptDelta));
	    newVolume += abs(min(0.0, v.x))* abs(min(0.0, v.y)) * texture2D(waterSimulation, ptC).z;
	    
	    ptC = vec2(max(pt.x - ptDelta.x, 0.0), pt.y);
	    v = unscaleVelocity(velocity(ptC, ptDelta));
	    newVolume += max(0.0, v.x) * (1.0 - abs(v.y)) * texture2D(waterSimulation, ptC).z;
	    
	    ptC = vec2(min(pt.x + ptDelta.x, 1.0), pt.y);
	    v = unscaleVelocity(velocity(ptC, ptDelta));
	    newVolume += abs(min(0.0, v.x)) * (1.0 - abs(v.y)) * texture2D(waterSimulation, ptC).z;
	    
	    ptC = vec2(max(pt.x - ptDelta.x, 0.0), max(pt.y - ptDelta.y, 0.0));
	    v = unscaleVelocity(velocity(ptC, ptDelta));
	    newVolume += max(0.0, v.x) * max(0.0, v.y) * texture2D(waterSimulation, ptC).z;
	    
	    ptC = vec2(pt.x, max(pt.y - ptDelta.y, 0.0));
	    v = unscaleVelocity(velocity(ptC, ptDelta));
	    newVolume += (1.0 - abs(v.x)) * max(0.0, v.y) * texture2D(waterSimulation, ptC).z;
	    
	    ptC = vec2(min(pt.x + ptDelta.x, 1.0), max(pt.y - ptDelta.y, 0.0));
	    v = unscaleVelocity(velocity(ptC, ptDelta));
	    newVolume += abs(min(0.0, v.x)) * max(0.0, v.y) * texture2D(waterSimulation, ptC).z;
	    
	    // Add a small amount of volume to simulate condensation
	    // Need to turn time into seconds
	    // newVolume += snoise(pt + (time * 0.001)) * (deltaTime * 0.001) * condensationRate;
	    // Add condensation
	    if (addWater) {
	      vec2 noise = cellular(pt / ptDelta * 0.1 + time);
	      // Scale the amount by height so the top gets more and the bottom less
	      newVolume += (noise.y - noise.x) * pt.y;
	    }
	    // newVolume += deltaTime * 0.1;
	    
	    return newVolume;
	  }
	  
	  void main() {
	    // The current cell on the texture
	    vec2 point = vUV;
	    // The amount you need to add or subtract from the current point
	    // to get to an adjacent point
	    vec2 pointDelta = vec2(1.0/textureSize);
	    
	    // Update the velocity and volume
	    // TO DO: calculate velocity and volume on septate passes
	    gl_FragColor = vec4(velocity(point, pointDelta), calcluateNewVolume(point, pointDelta), 1.0);
	   }
	</script>
	
	<script id="renderCondensationFS" type="x-shader/x-fragment">
	  precision mediump float;

	  uniform vec2 textureSize; //The width and height of the texture
	  // x = velocity x
	  // y = velocity y
	  // z = volume of water in grams
	  uniform sampler2D waterSimulation;
	  
	  varying vec2 vUV;
	  
	  void main() {
	    // The current cell on the texture
	    vec2 point = vUV;
	    // The amount you need to add or subtract from the current point
	    // to get to an adjacent point
	    vec2 pointDelta = vec2(1.0/textureSize);
	    
	    // Update the velocity and volume
	    // TO DO: calculate velocity and volume on septate passes
	    gl_FragColor = vec4(vec3(texture2D(waterSimulation, vUV).z), 1.0);
	    // if (texture2D(waterSimulation, vUV).x > 0.0) {
	    //   gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);
	    // }
	    // if (texture2D(waterSimulation, vUV).y == 0.0) {
	    //   gl_FragColor = vec4(1.0, 0.0, 1.0, 1.0);
	    // }
	    // if (texture2D(waterSimulation, vUV).y == 1.0) {
	    //   gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);
	    // }
	    // if (texture2D(waterSimulation, vUV).x != 0.5) {
	    //   gl_FragColor = vec4(0.0, 1.0, 1.0, 1.0);
	    // }
	   }
	</script>

	<script>

		// Load shaders
		var vs = document.getElementById( 'vertexShader' ).textContent;
		var passthroughVS = document.getElementById( 'passthroughVS' ).textContent;
  	var fs = document.getElementById( 'fragmentShader' ).textContent;
  	var simulateCondensationFS = document.getElementById('simulateCondensationFS').textContent;
  	var renderCondensationFS = document.getElementById('renderCondensationFS').textContent;

		// Declare variables
		var container;
		var camera, scene, renderer; // Camera scene
		var controls; // Camera controller
		var loader = new THREE.JSONLoader();

		// Skybox
		var skyMesh, cubeMap;
		
		// Load meshes and textures
		var mesh;
		var glassMesh;
		var texture1;

		// GUI
		var gui = new dat.GUI( { width: 350 } );
		
		// Condensation
		var waterBufferMaterial;
		var sceneCondensationMaterial;
		var condensationResX = 128;
		var condensationResY = 128;
		var condensationBufferScene;
		var condensationFBO_B;
		var condensationFBO_A;
		var orthoCamera;
		var addingWater = true;
		
		init();
		animate();

		// Initialize function
		function init() {

			// Initialize scene
			container = document.getElementById( 'container' );

			camera = new THREE.PerspectiveCamera( 50, window.innerWidth / window.innerHeight, 1, 2000 );
			camera.position.set( 0, 0, 5 );
			
			controls = new THREE.OrbitControls( camera );
			controls.update();

			scene = new THREE.Scene();
			scene.fog = new THREE.FogExp2( 0x000000, 0.035 );

			options = {
				index1: 1.0, // Index of air (vacuum)
				index2: 1.51714, // Index of glass
				fresBias: 0.15,
				fresPower: 2.0,
				};
			
			// -- Skybox
			//	Skybox Shaders
			var sb_vs = document.getElementById( 'skyboxVS' ).textContent;
			var sb_fs = document.getElementById( 'skyboxFS' ).textContent;
			
			// Geometry
			var geometry_sb = new THREE.BoxGeometry(2000,2000,2000);
			
			cubeMap = new THREE.CubeTextureLoader()
				.setPath("./cubemap/")
				.load( [
			'posx.jpg',
			'negx.jpg',
			'posy.jpg',
			'negy.jpg',
			'posz.jpg',
			'negz.jpg'
				] );
			
			// Condensation shader
			initCondensation();
			
			// Uniform
			var uniforms_sb = {"tCube": {type:"t",value:cubeMap}};
			
			// Material
			var material_sb = new THREE.RawShaderMaterial({
					uniforms:uniforms_sb,
					vertexShader:sb_vs,
					fragmentShader:sb_fs
				});
				
			material_sb.depthWrite = false;
			material_sb.side = THREE.BackSide;
			
			// Mesh
			skyMesh = new THREE.Mesh(geometry_sb,material_sb);
			scene.add(skyMesh);

			var uniforms = {
				tCube: {type: "t", value: cubeMap},
				index1: {type:"f", value:options.index1},
				index2: {type:"f",value:options.index2},
				fresBias: {type:"f",value:options.fresBias},
				fresPower: {type:"f",value:options.fresPower},
			}
			var geometry = new THREE.SphereGeometry(0.31,32,32)
			var material = new THREE.RawShaderMaterial({
					uniforms: uniforms,
					vertexShader: vs,
					fragmentShader: fs,
					});
			
			//var material = new THREE.MeshStandardMaterial({color:0x2194ce});
			mesh = new THREE.Mesh(geometry, material);
			scene.add(mesh);
			
			uniforms = {
				index1: {type:"f", value:options.index1},
				index2: {type:"f",value:options.index2},
				
				tCube: {type: "t", value: cubeMap},
				t1: { type: "t", value: texture1  },
				fresPower: {type:"f",value:options.fresPower},
			};

			material = new THREE.RawShaderMaterial( {
				uniforms: uniforms,
				vertexShader: vs,
				fragmentShader: fs,	
			} );

			// glassMesh = new THREE.Mesh( useGeometry, material );
			// gui.add( options, "index1", 1,5).onChange(function(value){
			// 	glassMesh.material.uniforms.index1.value = value;
			// });
			// gui.add( options, "index2", 1,5).onChange(function(value){
			// 	glassMesh.material.uniforms.index2.value = value;
			// });
			// gui.add( options, "fresPower", 1,5).onChange(function(value){
			// 	glassMesh.material.uniforms.index2.value = value;
			// });

			processBlenderObject('json/glass.json', material, new THREE.Vector3(0, -1.5, 0), new THREE.Vector3(0.012,0.012,0.012));
			
			processBlenderObject('json/cupnoodle.json', sceneCondensationMaterial, new THREE.Vector3(2, -1.5, 0), new THREE.Vector3(1.0,1.0,1.0));

			// Setup renderer
			renderer = new THREE.WebGLRenderer();
			renderer.setPixelRatio( window.devicePixelRatio );
			renderer.setSize( window.innerWidth, window.innerHeight );
			container.appendChild( renderer.domElement );

			window.addEventListener( 'resize', onWindowResize, false );
		}
		
		function processBlenderObject(path, material, position, scale) {
			loader.load( path, function(geometry, materials) {
				console.log(geometry);
				console.log(materials);

				mesh = new THREE.Mesh( geometry, material );

				//positioning and scaling blender obj so that it's in the center of the screen
				mesh.position.copy(position);
				mesh.scale.copy(scale);

				scene.add( mesh );
			} );
		}

		// Resize the renderer on window change
		function onWindowResize( event ) {

			renderer.setSize( window.innerWidth, window.innerHeight );

			camera.aspect = window.innerWidth / window.innerHeight;
			camera.updateProjectionMatrix();
		}


		// Animate, calls Render()
		function animate() {

			requestAnimationFrame( animate );
			render();
		}

		function render() {
			camera.lookAt( scene.position );
			renderCondensation();
			renderer.render( scene, camera );
		}

		// Prepares the required condensation shaders
		// Returns the material to be added to the main scene
		function initCondensation() {
			orthoCamera = new THREE.OrthographicCamera( window.innerWidth / -2, window.innerWidth / 2, window.innerHeight / 2, window.innerHeight / -2, 0.1, 1000 );
			orthoCamera.position.z = 0.2;
			
			//Create off-screen buffer scene
			condensationBufferScene = new THREE.Scene();
			
			//Create 2 buffer textures
			condensationFBO_A = new THREE.WebGLRenderTarget( condensationResX, condensationResY, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter});
			condensationFBO_B = new THREE.WebGLRenderTarget( condensationResX, condensationResY, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter} );
			
			var dataTexture = createWaterTexture();

			waterBufferMaterial = new THREE.RawShaderMaterial( {
			  uniforms: {
			    time: { type: "f", value: performance.now() },
			    deltaTime: { type: "f", value: 0.0 },
			    waterSimulation: { type: "t", value: dataTexture },
			    condensationRate: { type: 'f', value: 0.01 },
			    addWater: { type: 'b', value: addingWater },
			    textureSize : {type: "v2", value: new THREE.Vector2( condensationResX, condensationResY )}  //shader doesn't have access to these global variables, so pass in the resolution
			  },
			    vertexShader: passthroughVS,
			    fragmentShader: simulateCondensationFS
			} );

			//we can use a Three.js Plane Geometry along with the orthographic camera to create a "full screen quad"
			var plane = new THREE.PlaneBufferGeometry( window.innerWidth, window.innerHeight )

			var bufferObject = new THREE.Mesh( plane, waterBufferMaterial );
			condensationBufferScene.add(bufferObject);
			
			sceneCondensationMaterial = new THREE.RawShaderMaterial( {
			  uniforms: {
			    waterSimulation: { type: "t", value: dataTexture },
			    textureSize : {type: "v2", value: new THREE.Vector2( condensationResX, condensationResY )}
			  },
			    vertexShader: passthroughVS,
			    fragmentShader: renderCondensationFS
			} );
			
			return sceneCondensationMaterial;
		}
		
		// Does all post-processing and shader passes required for the condensation effect
		// before rendering the main scene
		function renderCondensation() {
			//Draw to the active offscreen buffer (whatever is stored in condensationFBO_B), that is the output of this rendering pass will be stored in the texture associated with condensationFBO_B
			renderer.render(condensationBufferScene, orthoCamera, condensationFBO_B);

			// Give the result of the simulation to the main scene
			sceneCondensationMaterial.uniforms.waterSimulation.value = condensationFBO_B.texture;

			//Now prepare for the next cycle by swapping condensationFBO_A and condensationFBO_B, so that the previous frame's *output* becomes the next frame's *input*
			var t = condensationFBO_A;
			condensationFBO_A = condensationFBO_B;
			condensationFBO_B = t;
			
			// Update uniforms
			var time = performance.now() * 0.001;
			waterBufferMaterial.uniforms.deltaTime.value = time - waterBufferMaterial.uniforms.time.value;
			waterBufferMaterial.uniforms.time.value = time;
			waterBufferMaterial.uniforms.addWater.value = addingWater;
			if (addingWater) {
			  // We want to pulse this for only one frame
			  addingWater = false;
			}
			// Reassign textures
			waterBufferMaterial.uniforms.waterSimulation.value = condensationFBO_A.texture;
		}
		
		// Creates the texture to be used for water simulation
		function createWaterTexture() {
		  // create a buffer with color data
		  
		  var size = condensationResX * condensationResY;
		  var data = new Uint8Array( 4 * size );

		  for ( var i = 0; i < size; i++ ) {
		    var stride = i * 4;
		    
		    // Randomly choose channels
		    data[ stride ] = 0;
		    data[ stride + 1 ] = 0;
		    data[ stride + 2 ] = 0;
		    data[ stride + 3 ] = 0;
		  }


		  // used the buffer to create a DataTexture
		  var texture = new THREE.DataTexture( data, condensationResX, condensationResY, THREE.RGBAFormat );
		  
		  texture.needsUpdate = true; // just a weird thing that Three.js wants you to do after you set the data for the texture

		  return texture;
		}


	</script>
	</body>
</html>

